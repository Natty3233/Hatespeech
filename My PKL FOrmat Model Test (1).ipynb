{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"12cK9JPaqdZLeOYdhu-yP4yyZucivNH5X","authorship_tag":"ABX9TyPma/lqEF5d/+ZOApowJtTd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TReAeH0nEC2w","colab":{"base_uri":"https://localhost:8080/"},"outputId":"98808a94-3450-4fee-f7ff-1a9e76bc500f"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","import pickle\n","from nltk.corpus import stopwords\n","from sklearn.tree import DecisionTreeClassifier\n","from nltk.stem.porter import *\n","import nltk\n","from sklearn.decomposition import PCA\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","\n","# Download the stopwords corpus\n","nltk.download('stopwords')\n","\n","\n","# Preprocess the text data (e.g., remove special characters, convert to lowercase)\n","# Custom stopwords list for Afan Oromo\n","dataset = pd.read_csv(\"/content/drive/My Drive/Hate speech/oromiffa.csv\")\n","dataset.drop('Unnamed: 2', inplace=True, axis=1)\n","dataset.drop('Unnamed: 3', inplace=True, axis=1)\n","# Preprocess the text data (e.g., remove special characters, convert to lowercase)\n","# Custom stopwords list for Afan Oromo\n","stop_words = ['akka', 'afaan', 'ah', 'akkuma', 'an', 'ani', 'anu', 'ayyaana', 'bara', 'biyya', 'buna', 'dha', 'dhalachu', 'dirqama', 'dubbi', 'gaafa', 'gala', 'gamtaa', 'gara', 'haa']\n","\n","def preprocess_text(posts):\n","    tokens = word_tokenize(posts)\n","    filtered_tokens = [token.lower() for token in tokens if token.lower() not in stop_words]\n","    processed_text = ' '.join(filtered_tokens)\n","    return processed_text\n","\n","dataset['processed_text'] = dataset['posts'].apply(preprocess_text)\n","\n","# Split the dataset into input (text) and target (label) variables\n","cv = CountVectorizer(stop_words=stop_words)\n","x = np.array(dataset['processed_text'])\n","X = cv.fit_transform(x)# Fit the Data\n","# Fit the Data\n","pca = PCA()  # n_components set to the default value\n","Y = pca.fit_transform(X.toarray())\n","\n","\n"]},{"cell_type":"code","source":["import pickle\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","import pickle\n","from nltk.corpus import stopwords\n","from sklearn.tree import DecisionTreeClassifier\n","from nltk.stem.porter import *\n","import nltk\n","from nltk.tokenize import word_tokenize\n","dataset = pd.read_csv(\"/content/drive/My Drive/Hate speech/amharic.csv\")\n","cv = CountVectorizer()\n","\n","cv.fit_transform(dataset[\"tweet\"].astype('U'))\n","# Fit the Data\n","# Load the pre-trained hate speech and offensive language detection model\n","# with open('/content/drive/My Drive/Telegram/EnglishModelHateSpeechModel.pkl', 'rb') as f:\n","#     hate_model = pickle.load(f)\n","# with open('/content/drive/My Drive/Telegram/MainWorkingAfaanOromooHateSpeechModel.pkl', 'rb') as f:\n","with open('/content/drive/My Drive/Telegram/AmharicModelHateSpeechModel.pkl', 'rb') as f:\n","    hate_model = pickle.load(f)\n","\n","#Predicting the outcome\n","inp =input(\"Enter the input post : ======>\")\n","dp = cv.transform([inp]).toarray()\n","dt=hate_model.predict(dp)\n","if dt=='Free':\n","    print(inp)\n","    \n","# elif dt=='Offensive Speech':\n","#     print(\"Warnnig.....\")\n","#     print(\"Warnnig.....\")\n","#     print(\"Warnnig.....\")\n","#     print(inp)\n","\n","else:\n","    print(\"///////////////////////////////\") \n","    print(\"/////the post is blocked//////\")\n","    print(\"//////////////////////////////\")\n","   \n","print(dt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rh1GKW0tJ9_o","executionInfo":{"status":"ok","timestamp":1684931562462,"user_tz":-180,"elapsed":13077,"user":{"displayName":"Naty Worku","userId":"05466235220466623091"}},"outputId":"73b4de41-bb64-4025-f933-479a15256bb4"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the input post : ======>ሰላም ነው\n","///////////////////////////////\n","/////the post is blocked//////\n","//////////////////////////////\n","['Hate']\n"]}]}]}